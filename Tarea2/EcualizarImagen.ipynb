{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgvOZ_qASegK",
        "outputId": "8ecdd8b1-0e3d-4d43-f730-969abc619622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-parJeE9Su5d",
        "outputId": "c1e06e5e-b079-49bf-8c14-b00724f13ed1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpsap8uogm\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "int main()\n",
        "{\n",
        "    std::cout << \"C++ Working\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7pJ8zgZSvuK",
        "outputId": "92076d20-4d6f-4ff0-dd4b-8b43825ca895"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C++ Working\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <sys/time.h>\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "using namespace std;\n",
        "\n",
        "#define SIZE 393216\n",
        "#define SECOND_TO_MRCROSECOND (1000000)\n",
        "#define NUM_BIN 768\n",
        "#define ARRAYSIZE 256\n",
        "\n",
        "__global__ void ecualizarImagen(int *d_a, int *d_acum) {\n",
        "    // Calcula el índice global del hilo\n",
        "    int idx = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    if(idx <= ARRAYSIZE)\n",
        "    {\n",
        "      // Normaliza la función de acumulación\n",
        "      int item = d_acum[idx];\n",
        "      //printf(\"Acumulado en posicion %d: %d \\n\", idx, item);\n",
        "      int result = (item*(ARRAYSIZE-1)) / SIZE;\n",
        "      //printf(\"Resultado Normalizado para %d: %d \\n\",idx, result);\n",
        "      d_a[idx] = result;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tint h_a[ARRAYSIZE]{ 2084,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,2,2,0,0,1,4137,0,2,1,1,0,2,5455,0,0,3,2,4,4845,5,7,0,6,4601,6,0,10,4728,18,0,5617,85,234,0,6261,886,887,5719,738,511,5715,458,450,6432,0,6130,231,100,5754,58,6259,23,5772,11,5526,20,5696,22,5013,0,6278,20,4850,0,5515,20,5054,0,4965,4523,77,5046,60,4345,4977,56,4818,4373,0,4648,4491,59,4024,7784,226,4004,3603,3834,101,3459,2923,2858,19,2921,2742,2462,2392,0,2409,2116,2071,1946,2242,2287,1952,0,2113,1722,1888,2181,2051,1952,1762,2741,2260,2121,2337,2659,2814,2117,2512,3147,1849,2636,2450,2091,1563,2251,2864,1884,1152,1109,1569,832,1239,2018,1240,908,877,1150,1719,869,756,1036,1467,757,755,903,1405,506,730,1284,688,558,1166,713,419,1046,574,946,426,558,906,489,818,415,936,462,811,421,784,391,789,446,776,316,754,460,684,719,376,717,380,702,667,406,672,705,369,706,763,804,325,803,850,382,937,965,943,1084,444,1226,1120,1225,1367,1838,670,1656,2066,2403,2098,1952,2921,2773,2323,2334,1929,2290,1534,2004,1812,1454,1083,1095,909,762,611,685,558,499,506,556,349,593,482,612,614,1006,1502,8001 };\n",
        "\tfloat h_b[ARRAYSIZE];\n",
        "  int h_acum[ARRAYSIZE];\n",
        "\tfor(int i = 0; i<ARRAYSIZE; ++i)\n",
        "  {\n",
        "\t\th_b[i] = h_a[i];\n",
        "    if (i == 0)\n",
        "        h_acum[i] = h_a[i];\n",
        "    else\n",
        "        h_acum[i] = h_acum[i-1] + h_a[i];\n",
        "\t}\n",
        "\n",
        "  std::cout << \"Starting declaration for device variables\" << std::endl;\n",
        "\n",
        "  std::cout << \"Creating acumulate array\" << std::endl;\n",
        "  std::cout << \"\\n[\";\n",
        "  for (int i = 0; i < ARRAYSIZE; i++)\n",
        "  {\n",
        "      //printf(\"bin %d : count %d\\n\", i, h_acum[i]);\n",
        "      std::cout << h_acum[i] << \", \";\n",
        "  }\n",
        "  std::cout << \"]\";\n",
        "  std::cout << \"Starting process\" << std::endl;\n",
        "\t// declare GPU memory pointers\n",
        "\tint *d_a;\n",
        "\tfloat *d_b;\n",
        "  int *d_acum;\n",
        "\n",
        "\t// allocate GPU memory\n",
        "\tcudaMalloc((void **)&d_a, ARRAYSIZE*sizeof(int));\n",
        "\t//cudaMalloc((void **)&d_b, ARRAYSIZE*sizeof(float));\n",
        "  cudaMalloc((void **)&d_acum, ARRAYSIZE*sizeof(int));\n",
        "\n",
        "\t// transfer the arrays to the GPU\n",
        "\tcudaMemcpy(d_a, h_a, ARRAYSIZE*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\t//cudaMemcpy(d_b, h_b, ARRAYSIZE*sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_acum, h_acum, ARRAYSIZE*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "\t//launch the kernel\n",
        "\n",
        "  ecualizarImagen <<<1,ARRAYSIZE>>>(d_a, d_acum);\n",
        "\t//histogram_atomic <<<((SIZE+NUM_BIN-1)/NUM_BIN), 1>>>(d_b, d_a);\n",
        "  std::cout << \"Process finished\" << std::endl << std::endl;\n",
        "\t// copy back the sum from GPU\n",
        "\tcudaMemcpy(h_a, d_a, ARRAYSIZE*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  std::cout << \"Equalized Histogram\" << std::endl << std::endl;\n",
        "  std::cout << \"\\n[\";\n",
        "  for (int i = 0; i < ARRAYSIZE; i++)\n",
        "  {\n",
        "\n",
        "      std::cout << h_a[i] << \", \";\n",
        "  }\n",
        "  std::cout << \"]\";\n",
        "\n",
        "\t// free GPU memory allocation\n",
        "\tcudaFree(d_a);\n",
        "\t//cudaFree(d_b);\n",
        "  cudaFree(d_acum);\n",
        "\n",
        "\treturn 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTfhff4RSzuA",
        "outputId": "e9f7754c-b0b8-4d3b-b90a-862c017fb95f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting declaration for device variables\n",
            "Creating acumulate array\n",
            "\n",
            "[2084, 2084, 2084, 2084, 2084, 2084, 2084, 2084, 2084, 2084, 2084, 2084, 2085, 2085, 2085, 2085, 2087, 2089, 2089, 2089, 2090, 6227, 6227, 6229, 6230, 6231, 6231, 6233, 11688, 11688, 11688, 11691, 11693, 11697, 16542, 16547, 16554, 16554, 16560, 21161, 21167, 21167, 21177, 25905, 25923, 25923, 31540, 31625, 31859, 31859, 38120, 39006, 39893, 45612, 46350, 46861, 52576, 53034, 53484, 59916, 59916, 66046, 66277, 66377, 72131, 72189, 78448, 78471, 84243, 84254, 89780, 89800, 95496, 95518, 100531, 100531, 106809, 106829, 111679, 111679, 117194, 117214, 122268, 122268, 127233, 131756, 131833, 136879, 136939, 141284, 146261, 146317, 151135, 155508, 155508, 160156, 164647, 164706, 168730, 176514, 176740, 180744, 184347, 188181, 188282, 191741, 194664, 197522, 197541, 200462, 203204, 205666, 208058, 208058, 210467, 212583, 214654, 216600, 218842, 221129, 223081, 223081, 225194, 226916, 228804, 230985, 233036, 234988, 236750, 239491, 241751, 243872, 246209, 248868, 251682, 253799, 256311, 259458, 261307, 263943, 266393, 268484, 270047, 272298, 275162, 277046, 278198, 279307, 280876, 281708, 282947, 284965, 286205, 287113, 287990, 289140, 290859, 291728, 292484, 293520, 294987, 295744, 296499, 297402, 298807, 299313, 300043, 301327, 302015, 302573, 303739, 304452, 304871, 305917, 306491, 307437, 307863, 308421, 309327, 309816, 310634, 311049, 311985, 312447, 313258, 313679, 314463, 314854, 315643, 316089, 316865, 317181, 317935, 318395, 319079, 319798, 320174, 320891, 321271, 321973, 322640, 323046, 323718, 324423, 324792, 325498, 326261, 327065, 327390, 328193, 329043, 329425, 330362, 331327, 332270, 333354, 333798, 335024, 336144, 337369, 338736, 340574, 341244, 342900, 344966, 347369, 349467, 351419, 354340, 357113, 359436, 361770, 363699, 365989, 367523, 369527, 371339, 372793, 373876, 374971, 375880, 376642, 377253, 377938, 378496, 378995, 379501, 380057, 380406, 380999, 381481, 382093, 382707, 383713, 385215, 393216, ]Starting process\n",
            "Process finished\n",
            "\n",
            "Equalized Histogram\n",
            "\n",
            "\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 7, 7, 7, 7, 7, 7, 10, 10, 10, 10, 10, 13, 13, 13, 13, 16, 16, 16, 20, 20, 20, 20, 24, 25, 25, 29, 30, 30, 34, 34, 34, 38, 38, 42, 42, 43, 46, 46, 50, 50, 54, 54, 58, 58, 61, 61, 65, 65, 69, 69, 72, 72, 76, 76, 79, 79, 82, 85, 85, 88, 88, 91, 94, 94, 98, 100, 100, 103, 106, 106, 109, 114, 114, 117, 119, 122, 122, 124, 126, 128, 128, 129, 131, 133, 134, 134, 136, 137, 139, 140, 141, 143, 144, 144, 146, 147, 148, 149, 151, 152, 153, 155, 156, 158, 159, 161, 163, 164, 166, 168, 169, 171, 172, 174, 175, 176, 178, 179, 180, 181, 182, 182, 183, 184, 185, 186, 186, 187, 188, 189, 189, 190, 191, 191, 192, 192, 193, 194, 194, 195, 195, 196, 196, 197, 197, 198, 198, 199, 199, 200, 200, 200, 201, 201, 202, 202, 203, 203, 203, 204, 204, 204, 205, 205, 206, 206, 206, 207, 207, 208, 208, 208, 209, 209, 209, 210, 210, 211, 211, 212, 212, 212, 213, 213, 214, 214, 215, 216, 216, 217, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 229, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 243, 243, 244, 244, 245, 245, 245, 246, 246, 246, 247, 247, 247, 248, 248, 249, 255, ]\n"
          ]
        }
      ]
    }
  ]
}